{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from numpy.fft import fft \n",
    "\n",
    "# Функция для создания окон и применения FFT\n",
    "def create_windows(data, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0, len(data) - window_size + 1, window_size):\n",
    "        window = data[i:i + window_size]\n",
    "        if window['class'].nunique() == 1:  # Проверяем, что в окне данные одного класса\n",
    "            # Применяем FFT к каждому признаку в окне\n",
    "            window_fft = np.abs(fft(window[features].values, axis=0))\n",
    "            X.append(window_fft)\n",
    "            y.append(window['class'].iloc[0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Функция для низкочастотной фильтрации\n",
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Загрузка данных из нескольких файлов\n",
    "file_paths = [os.path.join(r\"..\\preprocessed_data\", path) for path in os.listdir(r\"..\\preprocessed_data\")]\n",
    "data_list = []\n",
    "for file_path in file_paths:\n",
    "    temp_data = pd.read_csv(file_path)\n",
    "    data_list.append(temp_data)\n",
    "\n",
    "data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "features = ['ax', 'ay', 'az', 'gx', 'gy', 'gz']\n",
    "scaler = StandardScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "window_size_seconds = 2\n",
    "sampling_rate = 0.2\n",
    "window_size_samples = int(window_size_seconds / sampling_rate)\n",
    "X_windowed, y_windowed = create_windows(data, window_size_samples)\n",
    "\n",
    "# Кодирование классов и разделение данных\n",
    "unique_classes = np.unique(y_windowed)\n",
    "class_mapping = {label: idx for idx, label in enumerate(unique_classes)}\n",
    "y_windowed_encoded = np.vectorize(class_mapping.get)(y_windowed)\n",
    "y_windowed_categorical = to_categorical(y_windowed_encoded)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_windowed, y_windowed_categorical, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, InputLayer, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Добавление слоев\n",
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "# inputs = Input(shape=(X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "# \n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Conv2D(16, (1, 1), padding='valid')(x)  # Используем 1x1 свёртку для сохранения размерности\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# x = Conv2D(32, (2, 2), padding='valid')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Conv2D(32, (1, 1), padding='valid')(x)  # Используем 1x1 свёртку для сохранения размерности\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(128)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "x = LSTM(128, return_sequences=True) (inputs)\n",
    "x = LSTM(128) (x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(64) (x)\n",
    "x = Dropout(0.5)(x)\n",
    "prediction = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=prediction)\n",
    "\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='max', restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "\n",
    "dot_img_file = 'model_1.png'\n",
    "\n",
    "\n",
    "plot_model(model, to_file=dot_img_file, rankdir=\"LR\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.DataFrame(columns=[\"Type\",\"Shape\"])\n",
    "for layer in model.layers:\n",
    "    table = table.append({\"Type\": layer.__class__.__name__,\"Shape\":layer.output_shape}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Оценка модели на тестовых данных\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Тестовая потеря: {test_loss}, Тестовая точность: {test_acc}\")\n",
    "\n",
    "# Графики потерь и точности\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Обучение')\n",
    "plt.plot(history.history['val_loss'], label='Валидация')\n",
    "plt.title('График потерь')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Потери')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Обучение')\n",
    "plt.plot(history.history['val_accuracy'], label='Валидация')\n",
    "plt.title('График точности')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Точность')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Предсказания и матрица ошибок\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Предсказанные классы')\n",
    "plt.ylabel('Истинные классы')\n",
    "plt.title('Матрица ошибок')\n",
    "plt.show()\n",
    "\n",
    "# Отчет о классификации\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=unique_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
